{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" ! pip install -q kaggle\n\nfrom google.colab import files\n\nfiles.upload()\n\n! mkdir ~/.kaggle\n\n! cp kaggle.json ~/.kaggle/\n\n! chmod 600 ~/.kaggle/kaggle.json\n\n! kaggle datasets list\n","metadata":{"id":"FGZK462z6f6n","outputId":"3eda9bbe-804e-439c-d44b-84afdb0b5576"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets download -d emmarex/plantdisease","metadata":{"id":"j-zczhCX75Qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /content/plantdisease.zip","metadata":{"id":"ngYpQFIc787I","outputId":"b7441758-232a-4c42-9490-3e8ecd5c9a84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n","metadata":{"id":"wW_3o9Zh8WxO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nEpochs= 14\nlr= 1e-3\nBatchsize = 32\ndefault_image_size = tuple((128, 128))\nimage_size = 0\ndirectory_root = '../input/plantdisease'\nwidth=128\nheight=128\ndepth=3\n\n","metadata":{"id":"wzThNGgs9Q1o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"id":"FVh0iwX1-OaV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimage_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    print(root_dir)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list[:400]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")\nimage_size = len(image_list)\nprint (f\"total image processed {image_size} \")\n\n","metadata":{"id":"FMRzt3BG-drc","outputId":"ea777c67-4b32-4a14-c643-5c3c7dc19fb3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_labels = []\ncount=0\nfor label in label_list:\n    if label.split('_')[len(label.split('_'))-1] == 'healthy':\n        count+=1\n        image_labels.append(0)\n    else:\n        image_labels.append(1)","metadata":{"id":"ESv7jL6l-wYZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nimage_list = np.array(image_list, dtype=np.float16) \nimage_label=np.array(image_labels)\nimage_list=image_list.reshape(5725,128*128*3)\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\nx_res, y_res = sm.fit_resample(image_list, image_label)\n","metadata":{"id":"FGTcdQqgaBBO","outputId":"715c57e4-c3e9-4944-d95e-48fce0b65e8f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np_image_list=x_res.reshape(9546,128,128,3)\nimage_label=y_res","metadata":{"id":"PG1gL69lbgO1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(10,10))\nfor i in range (16):\n  n = random.randint(1,5000)\n  plt.subplot(4,4,i+1)\n  plt.xticks([])\n  plt.yticks([])\n  plt.grid(False)\n  plt.imshow((np_image_list[n]).astype(np.uint8))\n  plt.xlabel(image_label[n])\nplt.show()","metadata":{"id":"jhe_SCpPJfOh","outputId":"c82138d9-41c3-4620-d92b-c751dbfcfa68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np_image_list/=255","metadata":{"id":"wWSe-daQnZEy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_label, test_size=0.2,shuffle=True) ","metadata":{"id":"JaARd97BAUbj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimageaug = ImageDataGenerator(\n    \n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True,vertical_flip=True,\n    fill_mode=\"nearest\")","metadata":{"id":"p41HQo1iAcx5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Flatten,Dense,Dropout\nmodel = tf.keras.models.Sequential()\nfrom tensorflow.keras.layers import Activation\ninputShape = (height, width, depth)\n\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",activation='relu',input_shape=inputShape))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu',kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\n","metadata":{"id":"xvV_9JnEsAaK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"OT-otD4iClKx","outputId":"ae375dfb-64aa-4bb4-9030-1f0be1076bd2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmodel.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr, decay=lr/Epochs),metrics=[\"accuracy\"])","metadata":{"id":"5P2O8qFjDd5G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    imageaug.flow(x_train, y_train, batch_size=Batchsize),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) / Batchsize,\n    validation_steps=len(x_test)/Batchsize,\n    epochs=Epochs, verbose=1\n    )","metadata":{"id":"AqPJeJsgDz_4","outputId":"37413a8a-0a99-4e30-e517-434eff5fcb19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"id":"BNzBwtFTEMX-","outputId":"d725c3cb-c5c6-42dd-a240-b26cfce567fb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test,y_test)","metadata":{"id":"mjx5RK8drGoF","outputId":"62e032b0-e3da-4cfd-afdc-5be3aea51abd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix \ny_true=[]\nfor element in y_test:\n    y_true.append(element)\nprediction_proba= model.predict(x_test)\nprediction=[]\nfor pred in prediction_proba:\n  if pred >0.5:\n    prediction.append(1)\n  else:\n    prediction.append(0)\ncnf_matrix = confusion_matrix(y_true,prediction)","metadata":{"id":"mgLypHcxh0zs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix","metadata":{"id":"2w6s9DIfmQQ8","outputId":"a23a14e2-e6c6-4536-d921-aa7723683a19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport itertools\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","metadata":{"id":"3coyruFemSht","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nplot_confusion_matrix(cnf_matrix, classes=['1' , '0'],normalize=True,\n                      title='Confusion matrix, with normalization')\nplt.show()","metadata":{"id":"uMcZljlmmZle","outputId":"21ed120b-0e12-43a0-9082-cb73cd6296d5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('CNN_model.keras')","metadata":{"id":"dDMAd2KtmeK2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}